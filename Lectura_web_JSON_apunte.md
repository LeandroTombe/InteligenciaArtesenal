
## <div style="background-color:#57ffcfff;padding:8px;border-radius:8px">3. Lectura desde la web (APIs) y JSON ‚Üí pandas</div>

> Objetivo: **traer datos JSON desde una API web**, convertirlos a **estructuras de Python** y analizarlos con **pandas**. Luego, **persistir** de forma eficiente (Parquet / Pickle).

---

### üß† Idea general (flujo)
**API (HTTP)** ‚Üí **JSON (texto)** ‚Üí `response.json()` ‚Üí **dict/list de Python** ‚Üí `pandas.DataFrame` ‚Üí (opcional) **guardar** `to_parquet()` / `to_pickle()`

---

### 1) Pedir datos a una API (GET) y convertir a JSON
```python
import requests

url = "https://dummyjson.com/products"   # ejemplo p√∫blico
resp = requests.get(url)                 # 1) HTTP GET
data = resp.json()                       # 2) JSON ‚Üí dict/list (Python)
type(data), list(data.keys())[:5]        # inspecci√≥n r√°pida
```

**Tips:**  
- `resp.status_code == 200` ‚áí OK.  
- `resp.json()` es igual a `json.loads(resp.text)` pero m√°s directo.  
- Muchos endpoints devuelven un objeto con una **lista** por dentro, p. ej. `data["products"]`.

---

### 2) Pasar JSON a DataFrame
```python
import pandas as pd

items = data["products"]                 # lista de objetos JSON
df = pd.DataFrame(items)                 # columnas = claves del JSON
df.head()
```

Si hay **campos anidados** (p. ej., `rating.details.stars`), us√°:
```python
from pandas import json_normalize

df_flat = json_normalize(items)          # "aplana" estructuras anidadas
df_flat.filter(like="rating").head()     # ejemplo: ver columnas relacionadas
```

---

### 3) Seleccionar solo lo √∫til (columnas)
```python
cols = ["id", "title", "brand", "price", "rating"]
df_view = df_flat[cols]
df_view.head()
```

> Consejo: manten√© un subconjunto **m√≠nimo** de columnas para acelerar an√°lisis y visualizaciones.

---

### 4) Limpieza r√°pida (valores faltantes y tipos)
```python
# Reemplazar null ‚Üí None en Python ya viene mapeado; luego:
df_view = df_view.copy()
df_view["price"] = pd.to_numeric(df_view["price"], errors="coerce")
df_view["rating"] = pd.to_numeric(df_view["rating"], errors="coerce")
df_view.isna().mean().round(3)           # % faltantes por columna
```

---

### 5) Guardar eficientemente (Parquet / Pickle)
- **Parquet** (columnar, comprimido, portable): ideal para tablas y lectura por columna.  
- **Pickle** (Python-only): √∫til para objetos de Python; menos portable.

```python
# Parquet (recomendado para data tabular)
df_view.to_parquet("products.parquet", engine="pyarrow", compression="snappy")

# Leer Parquet (y opcional: solo algunas columnas)
df_pq = pd.read_parquet("products.parquet", columns=["id", "title", "price"])
df_pq.head()

# Pickle (si necesit√°s guardar el objeto tal cual, solo para Python)
df_view.to_pickle("products.pkl")
df_pk = pd.read_pickle("products.pkl")
```

---

### 6) (Opcional) Persistir en SQLite / MongoDB
Como en tu notebook aparecen `sqlite3` y `pymongo`, ac√° queda el ‚Äúbridge‚Äù m√≠nimo:

**SQLite (local, archivo `.db`):**
```python
import sqlite3
con = sqlite3.connect("products.db")
df_view.to_sql("products", con, if_exists="replace", index=False)
pd.read_sql("SELECT id, title, price FROM products LIMIT 5", con)
con.close()
```

**MongoDB (colecci√≥n de documentos JSON):**
```python
from pymongo import MongoClient

client = MongoClient("mongodb://localhost:27017/")   # ajust√° la URI
db = client["ejemplo_db"]                            # visto en tu notebook
docs = df_view.to_dict(orient="records")
db.libros.insert_many(docs)                          # o la colecci√≥n que uses
db.libros.find_one()
```

> Eleg√≠ **SQLite** si quer√©s SQL r√°pido en un archivo local. Eleg√≠ **MongoDB** si tu JSON es muy **anidado** y prefer√≠s un esquema flexible.

---
